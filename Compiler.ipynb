{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiler Project\n",
    "Development of a simple compiler for C++ code, executed in three distinct phases: Lexical Analysis, Top-Down Parsing, and Three-Address Code Generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiler Project Documentation\n",
    "\n",
    "#### Introduction\n",
    "This project involved the development of a simple compiler for C++ code, executed in three distinct phases: Lexical Analysis, Top-Down Parsing, and Three-Address Code Generation. Each phase built upon the previous one, refining and expanding the compiler's capabilities. By the end of the project, a functional compiler capable of generating intermediate three-address code from simple C++ source code was achieved.\n",
    "\n",
    "#### Phase 1: Lexical Analyzer\n",
    "In the first phase, a lexical analyzer was developed. The main tasks completed during this phase were:\n",
    "\n",
    "##### Tokenization\n",
    "The lexical analyzer scanned the input C++ source code and converted it into a sequence of tokens. Tokens include keywords, identifiers and operators.\n",
    "\n",
    "##### Regular Expressions\n",
    "Regular expressions were used to define the patterns for different tokens.\n",
    "\n",
    "#### Phase 2: Top-Down Parser\n",
    "The second phase focused on developing a top-down parser, specifically a recursive descent parser. Key tasks accomplished included:\n",
    "\n",
    "##### Grammar Definition\n",
    "The context-free grammar (CFG) for a subset of the C++ language was defined. This grammar was designed to be LL(1) to facilitate top-down parsing.\n",
    "\n",
    "##### Parser Implementation\n",
    "Using the CFG, a recursive descent parser was implemented. The parser takes the token stream produced by the lexical analyzer and constructs a parse tree.\n",
    "\n",
    "#### Phase 3: Three-Address Code Generator\n",
    "In the final phase, the compiler was extended to generate three-address code (TAC), an intermediate representation of the source code. Key developments in this phase were:\n",
    "\n",
    "##### Grammar Refinement\n",
    "The grammar defined in the second phase was modified to better suit the needs of code generation.\n",
    "\n",
    "##### Parse Tree to TAC Conversion\n",
    "Algorithms were developed to traverse the parse tree and generate corresponding three-address code.\n",
    "\n",
    "##### Optimization\n",
    "Basic optimizations were implemented to produce more efficient intermediate code.\n",
    "\n",
    "#### Conclusion\n",
    "This project culminated in a fully functional simple C++ compiler capable of performing lexical analysis, parsing, and generating three-address code. The iterative development approach ensured that each phase built upon the previous one, leading to a coherent and integrated compiler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1: Lexical Analyzer\n",
    "\n",
    "The first phase of the compiler project involves developing a lexical analyzer. The primary tasks in this phase are tokenization, defining regular expressions for various token types.\n",
    "\n",
    "#### Token Types Definition\n",
    "\n",
    "The `TOKEN_SPECIFICATION` defines various token types and their corresponding regular expression patterns. Key token types include:\n",
    "\n",
    "- **INCLUDE**: Matches preprocessor include directives (e.g., `#include <iostream>`).\n",
    "- **USING**: Matches using namespace directives (e.g., `using namespace std;`).\n",
    "- **STD_CIN**: Matches standard input streams (e.g., `std::cin` or `cin`).\n",
    "- **STD_COUT**: Matches standard output streams (e.g., `std::cout` or `cout`).\n",
    "- **TYPE**: Matches basic data types (e.g., `int`, `void`, `double`, `float`).\n",
    "- **NUMBER**: Matches integer numbers.\n",
    "- **WHILE**: Matches the `while` keyword.\n",
    "- **IF**: Matches the `if` keyword.\n",
    "- **ELSE**: Matches the `else` keyword.\n",
    "- **RETURN**: Matches the `return` keyword.\n",
    "- **IDENTIFIER**: Matches variable names and function names (e.g., `main`, `variableName`).\n",
    "- **OP**: Matches operators (e.g., `+`, `-`, `*`, `/`, `==`, `!=`, `<=`, `>=`, `<`, `>`).\n",
    "- **ASSIGN**: Matches the assignment operator (`=`).\n",
    "- **SEMICOLON**: Matches the semicolon (`;`).\n",
    "- **LPAREN**: Matches the left parenthesis (`(`).\n",
    "- **RPAREN**: Matches the right parenthesis (`)`).\n",
    "- **LBRACE**: Matches the left brace (`{`).\n",
    "- **RBRACE**: Matches the right brace (`}`).\n",
    "- **STRING_LITERAL**: Matches string literals (e.g., `\"hello\"`).\n",
    "- **NEWLINE**: Matches newline characters.\n",
    "- **SKIP**: Matches spaces and tabs, which are ignored.\n",
    "- **MISMATCH**: Matches any other character not defined in the previous tokens, used for error handling.\n",
    "\n",
    "#### Token Regex Combination\n",
    "\n",
    "The token patterns are combined into a single regular expression using named groups. This combined regex is used to match and identify tokens in the input code.\n",
    "\n",
    "#### Lexical Analysis Function\n",
    "\n",
    "The `lex` function performs lexical analysis by scanning the input C++ code and producing a list of tokens. It uses regular expression matching to identify token types and their values. Special cases such as newlines and spaces are ignored, while any unexpected characters raise an error.\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "This phase lays the groundwork for subsequent phases by converting the input C++ code into a sequence of tokens. These tokens represent meaningful components of the code, facilitating further parsing and code generation in later stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define token types\n",
    "TOKEN_SPECIFICATION = [\n",
    "    ('INCLUDE',      r'#include <[a-zA-Z0-9_]+>'),\n",
    "    ('USING',        r'using namespace [a-zA-Z0-9_]+;'),\n",
    "    ('STD_CIN',      r'std::cin|cin'),  # Added combined token for cin\n",
    "    ('STD_COUT',     r'std::cout|cout'),  # Added combined token for cout\n",
    "    ('TYPE',         r'\\bint\\b|\\bvoid\\b|\\bdouble\\b|\\bfloat\\b'),\n",
    "    ('NUMBER',       r'\\b\\d+\\b'),\n",
    "    ('WHILE',        r'\\bwhile\\b'),\n",
    "    ('IF',           r'\\bif\\b'),\n",
    "    ('ELSE',         r'\\belse\\b'),\n",
    "    ('RETURN',       r'\\breturn\\b'),\n",
    "    ('IDENTIFIER',   r'\\b[a-zA-Z_][a-zA-Z0-9_]*\\b'),\n",
    "    ('OP',           r'<<|>>|\\+|\\-|\\*|\\/|==|!=|<=|>=|<|>'),\n",
    "    ('ASSIGN',       r'='),\n",
    "    ('SEMICOLON',    r';'),\n",
    "    ('LPAREN',       r'\\('),\n",
    "    ('RPAREN',       r'\\)'),\n",
    "    ('LBRACE',       r'\\{'),\n",
    "    ('RBRACE',       r'\\}'),\n",
    "    ('STRING_LITERAL', r'\"[^\"]*\"'),\n",
    "    ('NEWLINE',      r'\\n'),\n",
    "    ('SKIP',         r'[ \\t]+'),\n",
    "    ('MISMATCH',     r'.'),  # Any other character\n",
    "]\n",
    "\n",
    "token_regex = '|'.join(f'(?P<{pair[0]}>{pair[1]})' for pair in TOKEN_SPECIFICATION)\n",
    "\n",
    "def lex(code: str) -> List[Tuple[str, str]]:\n",
    "    tokens = []\n",
    "    for mo in re.finditer(token_regex, code):\n",
    "        kind = mo.lastgroup\n",
    "        value = mo.group()\n",
    "        if kind == 'NEWLINE':\n",
    "            continue\n",
    "        elif kind == 'SKIP':\n",
    "            continue\n",
    "        elif kind == 'MISMATCH':\n",
    "            raise RuntimeError(f'{value!r} unexpected')\n",
    "        else:\n",
    "            tokens.append((kind, value))\n",
    "            print(f'Token: {kind}, Value: {value}')  # Debug statement\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2: Top-Down Parser\n",
    "\n",
    "The second phase of the compiler project involves developing a top-down parser using a recursive descent approach. This parser takes the token stream produced by the lexical analyzer and constructs a parse tree representing the structure of the program.\n",
    "\n",
    "#### Parser Class\n",
    "\n",
    "The `Parser` class is responsible for parsing the token stream. It maintains the current position in the token list and provides methods to match and process various language constructs.\n",
    "\n",
    "#### Key Methods and Their Functions\n",
    "\n",
    "- **Initialization (`__init__`)**: Initializes the parser with a list of tokens and sets the initial position to zero.\n",
    "\n",
    "- **Parsing Entry Point (`parse`)**: Begins the parsing process by invoking the `program` method.\n",
    "\n",
    "- **Token Matching (`match`)**: Ensures that the current token matches the expected type and advances the position. Raises a `SyntaxError` if the token does not match.\n",
    "\n",
    "#### Parsing Program Structure\n",
    "\n",
    "- **Program (`program`)**: Parses the entire program, including include directives, namespace declaration, and function definitions.\n",
    "\n",
    "- **Include Directives (`include_directives`)**: Collects all `#include` directives at the beginning of the program.\n",
    "\n",
    "- **Namespace Declaration (`namespace_declaration`)**: Parses the `using namespace` directive, if present.\n",
    "\n",
    "- **Function Definitions (`function_definitions`)**: Parses one or more function definitions in the program.\n",
    "\n",
    "#### Parsing Function and Statements\n",
    "\n",
    "- **Function Definition (`function_definition`)**: Parses a function's return type, name, parameters, and body.\n",
    "\n",
    "- **Parameters (`parameters`)**: Parses function parameters, handling multiple parameters separated by commas.\n",
    "\n",
    "- **Statements (`statements`)**: Parses a block of statements within a function or control structure.\n",
    "\n",
    "- **Individual Statement (`statement`)**: Determines the type of statement (variable declaration, assignment, control structures, etc.) and delegates parsing to the appropriate method.\n",
    "\n",
    "#### Handling Specific Statements\n",
    "\n",
    "- **Variable Declaration (`variable_declaration`)**: Parses variable declarations, including optional initialization.\n",
    "\n",
    "- **Assignment (`assignment`)**: Parses assignment statements.\n",
    "\n",
    "- **If Statement (`if_statement`)**: Parses `if` statements with optional `else` branches.\n",
    "\n",
    "- **While Statement (`while_statement`)**: Parses `while` loops.\n",
    "\n",
    "- **Return Statement (`return_statement`)**: Parses `return` statements.\n",
    "\n",
    "- **Output Statement (`output_statement`)**: Parses `std::cout` statements.\n",
    "\n",
    "- **Input Statement (`input_statement`)**: Parses `std::cin` statements.\n",
    "\n",
    "#### Parsing Expressions\n",
    "\n",
    "- **Expression (`expression`)**: Parses expressions, handling binary operators.\n",
    "\n",
    "- **Term (`term`)**: Parses terms within expressions, handling multiplication and division.\n",
    "\n",
    "- **Factor (`factor`)**: Parses factors, which can be numbers, string literals, identifiers, or parenthesized expressions. Handles function calls if an identifier is followed by parentheses.\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "The parser is a crucial component of the compiler, transforming a linear sequence of tokens into a hierarchical structure that reflects the syntactic organization of the source code. This structured representation is essential for subsequent phases, such as semantic analysis and code generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self, tokens: List[Tuple[str, str]]):\n",
    "        self.tokens = tokens\n",
    "        self.pos = 0\n",
    "\n",
    "    def parse(self):\n",
    "        return self.program()\n",
    "\n",
    "    def match(self, expected_type):\n",
    "        if self.pos < len(self.tokens) and self.tokens[self.pos][0] == expected_type:\n",
    "            print(f'Matched {expected_type} at position {self.pos}, token: {self.tokens[self.pos]}')  # Debug statement\n",
    "            self.pos += 1\n",
    "        else:\n",
    "            raise SyntaxError(f'Expected {expected_type} but found {self.tokens[self.pos][0]} at position {self.pos}')\n",
    "\n",
    "    def program(self):\n",
    "        includes = self.include_directives()\n",
    "        namespace = self.namespace_declaration()\n",
    "        functions = self.function_definitions()\n",
    "        return {'type': 'program', 'includes': includes, 'namespace': namespace, 'functions': functions}\n",
    "\n",
    "    def include_directives(self):\n",
    "        includes = []\n",
    "        while self.pos < len(self.tokens) and self.tokens[self.pos][0] == 'INCLUDE':\n",
    "            includes.append(self.tokens[self.pos][1])\n",
    "            self.pos += 1\n",
    "        return includes\n",
    "\n",
    "    def namespace_declaration(self):\n",
    "        if self.pos < len(self.tokens) and self.tokens[self.pos][0] == 'USING':\n",
    "            namespace = self.tokens[self.pos][1]\n",
    "            self.pos += 1\n",
    "            return namespace\n",
    "        return None\n",
    "\n",
    "    def function_definitions(self):\n",
    "        functions = []\n",
    "        while self.pos < len(self.tokens):\n",
    "            functions.append(self.function_definition())\n",
    "        return functions\n",
    "\n",
    "    def function_definition(self):\n",
    "        return_type = self.tokens[self.pos][1]\n",
    "        self.pos += 1\n",
    "        name = self.tokens[self.pos][1]\n",
    "        self.pos += 1\n",
    "        self.match('LPAREN')\n",
    "        params = self.parameters()\n",
    "        self.match('RPAREN')\n",
    "        self.match('LBRACE')\n",
    "        body = self.statements()\n",
    "        self.match('RBRACE')\n",
    "        return {'type': 'function', 'return_type': return_type, 'name': name, 'params': params, 'body': body}\n",
    "\n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        while self.pos < len(self.tokens) and self.tokens[self.pos][0] != 'RPAREN':\n",
    "            param_type = self.tokens[self.pos][1]\n",
    "            self.pos += 1\n",
    "            param_name = self.tokens[self.pos][1]\n",
    "            self.pos += 1\n",
    "            params.append((param_type, param_name))\n",
    "            if self.pos < len(self.tokens) and self.tokens[self.pos][0] == 'RPAREN':\n",
    "                break\n",
    "        return params\n",
    "\n",
    "    def statements(self):\n",
    "        statements = []\n",
    "        while self.pos < len(self.tokens) and self.tokens[self.pos][0] != 'RBRACE':\n",
    "            statements.append(self.statement())\n",
    "        return statements\n",
    "\n",
    "    def statement(self):\n",
    "        if self.tokens[self.pos][0] == 'TYPE':\n",
    "            return self.variable_declaration()\n",
    "        elif self.tokens[self.pos][0] == 'IDENTIFIER' and self.tokens[self.pos + 1][0] == 'ASSIGN':\n",
    "            return self.assignment()\n",
    "        elif self.tokens[self.pos][0] == 'IF':\n",
    "            return self.if_statement()\n",
    "        elif self.tokens[self.pos][0] == 'WHILE':\n",
    "            print('into WHILE statement')\n",
    "            return self.while_statement()\n",
    "        elif self.tokens[self.pos][0] == 'RETURN':\n",
    "            return self.return_statement()\n",
    "        elif self.tokens[self.pos][0] == 'STD_COUT':\n",
    "            return self.output_statement()\n",
    "            print('into CIN statement ...')\n",
    "        elif self.tokens[self.pos][0] == 'STD_CIN':\n",
    "            return self.input_statement()\n",
    "        else:\n",
    "            expr = self.expression()\n",
    "            if self.pos < len(self.tokens) and self.tokens[self.pos][0] == 'SEMICOLON':\n",
    "                self.match('SEMICOLON')\n",
    "            return expr\n",
    "\n",
    "    def variable_declaration(self):\n",
    "        var_type = self.tokens[self.pos][1]\n",
    "        self.pos += 1\n",
    "        var_name = self.tokens[self.pos][1]\n",
    "        self.pos += 1\n",
    "        if self.pos < len(self.tokens) and self.tokens[self.pos][0] == 'ASSIGN':\n",
    "            self.pos += 1\n",
    "            value = self.expression()\n",
    "            self.match('SEMICOLON')\n",
    "            return {'type': 'var_declaration', 'var_type': var_type, 'var_name': var_name, 'value': value}\n",
    "        self.match('SEMICOLON')\n",
    "        return {'type': 'var_declaration', 'var_type': var_type, 'var_name': var_name}\n",
    "\n",
    "    def assignment(self):\n",
    "        var_name = self.tokens[self.pos][1]\n",
    "        self.pos += 1\n",
    "        self.match('ASSIGN')\n",
    "        value = self.expression()\n",
    "        self.match('SEMICOLON')\n",
    "        return {'type': 'assignment', 'var_name': var_name, 'value': value}\n",
    "\n",
    "    def if_statement(self):\n",
    "        self.match('IF')\n",
    "        self.match('LPAREN')\n",
    "        condition = self.expression()\n",
    "        self.match('RPAREN')\n",
    "        self.match('LBRACE')\n",
    "        then_branch = self.statements()\n",
    "        self.match('RBRACE')\n",
    "        else_branch = None\n",
    "        if self.pos < len(self.tokens) and self.tokens[self.pos][0] == 'ELSE':\n",
    "            self.pos += 1\n",
    "            self.match('LBRACE')\n",
    "            else_branch = self.statements()\n",
    "            self.match('RBRACE')\n",
    "        return {'type': 'if', 'condition': condition, 'then': then_branch, 'else': else_branch}\n",
    "\n",
    "    def while_statement(self):\n",
    "        self.match('WHILE')\n",
    "        self.match('LPAREN')\n",
    "        condition = self.expression()\n",
    "        self.match('RPAREN')\n",
    "        self.match('LBRACE')\n",
    "        body = self.statements()\n",
    "        self.match('RBRACE')\n",
    "        return {'type': 'while', 'condition': condition, 'body': body}\n",
    "\n",
    "    def return_statement(self):\n",
    "        self.match('RETURN')\n",
    "        value = self.expression()\n",
    "        self.match('SEMICOLON')\n",
    "        return {'type': 'return', 'value': value}\n",
    "\n",
    "    def output_statement(self):\n",
    "        self.match('STD_COUT')\n",
    "        self.match('OP')  # Match '<<'\n",
    "        expressions = []\n",
    "        expressions.append(self.expression())\n",
    "        while self.pos < len(self.tokens) and self.tokens[self.pos][0] == 'OP' and self.tokens[self.pos][1] == '<<':\n",
    "            self.pos += 1\n",
    "            expressions.append(self.expression())\n",
    "        self.match('SEMICOLON')\n",
    "        return {'type': 'output', 'expressions': expressions}\n",
    "\n",
    "    def input_statement(self):\n",
    "        self.match('STD_CIN')\n",
    "        print('CIN Matched ...')\n",
    "        self.match('OP')  # Match '>>'\n",
    "        variables = []\n",
    "        variables.append(self.expression())\n",
    "        while self.pos < len(self.tokens) and self.tokens[self.pos][0] == 'OP' and self.tokens[self.pos][1] == '>>':\n",
    "            self.pos += 1\n",
    "            variables.append(self.expression())\n",
    "        self.match('SEMICOLON')\n",
    "        return {'type': 'input', 'variables': variables}\n",
    "\n",
    "    def expression(self):\n",
    "        expr = self.term()\n",
    "        while self.pos < len(self.tokens) and self.tokens[self.pos][0] == 'OP' and self.tokens[self.pos][1] in ('+', '-', '>=', '<=', '==', '!=', '>', '<'):\n",
    "            op = self.tokens[self.pos][1]\n",
    "            self.pos += 1\n",
    "            right = self.term()\n",
    "            expr = {'type': 'binary_op', 'operator': op, 'left': expr, 'right': right}\n",
    "        return expr\n",
    "\n",
    "    def term(self):\n",
    "        expr = self.factor()\n",
    "        while self.pos < len(self.tokens) and self.tokens[self.pos][0] == 'OP' and self.tokens[self.pos][1] in ('*', '/'):\n",
    "            op = self.tokens[self.pos][1]\n",
    "            self.pos += 1\n",
    "            right = self.factor()\n",
    "            expr = {'type': 'binary_op', 'operator': op, 'left': expr, 'right': right}\n",
    "        return expr\n",
    "\n",
    "    def factor(self):\n",
    "        if self.tokens[self.pos][0] == 'LPAREN':\n",
    "            self.match('LPAREN')\n",
    "            expr = self.expression()\n",
    "            self.match('RPAREN')\n",
    "            return expr\n",
    "        elif self.tokens[self.pos][0] == 'NUMBER':\n",
    "            self.pos += 1\n",
    "            return {'type': 'number', 'value': self.tokens[self.pos - 1][1]}\n",
    "        elif self.tokens[self.pos][0] == 'STRING_LITERAL':\n",
    "            self.pos += 1\n",
    "            return {'type': 'string', 'value': self.tokens[self.pos - 1][1]}\n",
    "        elif self.tokens[self.pos][0] == 'IDENTIFIER':\n",
    "            identifier = self.tokens[self.pos][1]\n",
    "            self.pos += 1\n",
    "            if self.pos < len(self.tokens) and self.tokens[self.pos][0] == 'LPAREN':\n",
    "                self.match('LPAREN')\n",
    "                args = []\n",
    "                if self.tokens[self.pos][0] != 'RPAREN':\n",
    "                    args.append(self.expression())\n",
    "                    while self.tokens[self.pos][0] == 'COMMA':\n",
    "                        self.match('COMMA')\n",
    "                        args.append(self.expression())\n",
    "                self.match('RPAREN')\n",
    "                return {'type': 'function_call', 'name': identifier, 'args': args}\n",
    "            return {'type': 'identifier', 'value': identifier}\n",
    "        else:\n",
    "            raise SyntaxError(f'Unexpected token: {self.tokens[self.pos][0]} at position {self.pos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 3: Three-Address Code (TAC) Generator\n",
    "\n",
    "The final phase of the compiler project involves generating Three-Address Code (TAC) from the Abstract Syntax Tree (AST) produced by the parser. This intermediate representation is crucial for optimization and translation into machine code.\n",
    "\n",
    "#### TAC Generation Function\n",
    "\n",
    "The `generate_tac` function converts the AST into TAC instructions. It traverses the AST recursively, generating appropriate TAC instructions for each node type.\n",
    "\n",
    "#### Key Components\n",
    "\n",
    "- **Temporary Variables (`new_temp`)**: Generates unique temporary variable names for intermediate results.\n",
    "\n",
    "#### Generating TAC for Various Nodes\n",
    "\n",
    "- **Program (`program`)**: Processes each function in the program.\n",
    "- **Function (`function`)**: Adds a label for the function name and generates TAC for each statement in the function body.\n",
    "- **Variable Declaration (`var_declaration`)**: Generates TAC for variable initialization.\n",
    "- **Assignment (`assignment`)**: Generates TAC for assignment statements.\n",
    "- **Binary Operation (`binary_op`)**: Generates TAC for binary operations, using temporary variables for intermediate results.\n",
    "- **Number (`number`)**: Returns the numeric value.\n",
    "- **Identifier (`identifier`)**: Returns the variable name.\n",
    "- **Function Call (`function_call`)**: Generates TAC for function calls, including arguments and return values.\n",
    "- **While Loop (`while`)**: Generates TAC for while loops, including conditional and jump instructions.\n",
    "- **If Statement (`if`)**: Generates TAC for if statements, including conditional and jump instructions.\n",
    "- **Return Statement (`return`)**: Generates TAC for return statements.\n",
    "- **Output Statement (`output`)**: Generates TAC for output statements (`std::cout`).\n",
    "- **Input Statement (`input`)**: Generates TAC for input statements (`std::cin`).\n",
    "\n",
    "#### Integration with Parsing\n",
    "\n",
    "The `parse_cpp_with_tac` function integrates lexical analysis, parsing, and TAC generation. It processes the input code to produce tokens, constructs the AST, and generates TAC. The resulting TAC is saved to a specified output file.\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "The TAC generator transforms the high-level AST into a lower-level intermediate representation, bridging the gap between the source code and machine code. This phase is essential for enabling further optimizations and efficient code generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAC Generation\n",
    "def generate_tac(ast):\n",
    "    tac = []\n",
    "    temp_count = 0  # Move this line outside of the generate function\n",
    "\n",
    "    def new_temp():\n",
    "        nonlocal temp_count\n",
    "        temp = f't{temp_count}'\n",
    "        temp_count += 1\n",
    "        return temp\n",
    "\n",
    "    def generate(node):\n",
    "        nonlocal temp_count  # Add this line to ensure temp_count is accessible\n",
    "        if node['type'] == 'program':\n",
    "            for func in node['functions']:\n",
    "                generate(func)\n",
    "        elif node['type'] == 'function':\n",
    "            tac.append((node['name'], ':'))\n",
    "            for stmt in node['body']:\n",
    "                generate(stmt)\n",
    "        elif node['type'] == 'var_declaration':\n",
    "            if 'value' in node:\n",
    "                value = generate(node['value'])\n",
    "                tac.append((node['var_name'], '=', value))\n",
    "        elif node['type'] == 'assignment':\n",
    "            value = generate(node['value'])\n",
    "            tac.append((node['var_name'], '=', value))\n",
    "        elif node['type'] == 'binary_op':\n",
    "            left = generate(node['left'])\n",
    "            right = generate(node['right'])\n",
    "            result = new_temp()\n",
    "            tac.append((result, '=', left, node['operator'], right))\n",
    "            return result\n",
    "        elif node['type'] == 'number':\n",
    "            return node['value']\n",
    "        elif node['type'] == 'identifier':\n",
    "            return node['value']\n",
    "        elif node['type'] == 'function_call':\n",
    "            args = [generate(arg) for arg in node['args']]\n",
    "            result = new_temp()\n",
    "            tac.append((result, '=', node['name'], '(', ', '.join(args), ')'))\n",
    "            return result\n",
    "        elif node['type'] == 'while':\n",
    "            start_label = f\"L{temp_count}\"\n",
    "            temp_count += 1\n",
    "            end_label = f\"L{temp_count}\"\n",
    "            temp_count += 1\n",
    "            tac.append((start_label, ':'))\n",
    "            cond = generate(node['condition'])\n",
    "            tac.append(('if', cond, '==', '0', 'goto', end_label))\n",
    "            for stmt in node['body']:\n",
    "                generate(stmt)\n",
    "            tac.append(('goto', start_label))\n",
    "            tac.append((end_label, ':'))\n",
    "        elif node['type'] == 'if':\n",
    "            else_label = f\"L{temp_count}\"\n",
    "            temp_count += 1\n",
    "            end_label = f\"L{temp_count}\"\n",
    "            temp_count += 1\n",
    "            cond = generate(node['condition'])\n",
    "            tac.append(('if', cond, '==', '0', 'goto', else_label))\n",
    "            for stmt in node['then']:\n",
    "                generate(stmt)\n",
    "            tac.append(('goto', end_label))\n",
    "            tac.append((else_label, ':'))\n",
    "            if 'else' in node:\n",
    "                for stmt in node['else']:\n",
    "                    generate(stmt)\n",
    "            tac.append((end_label, ':'))\n",
    "        elif node['type'] == 'return':\n",
    "            value = generate(node['value'])\n",
    "            tac.append(('return', value))\n",
    "        elif node['type'] == 'output':\n",
    "            for expr in node['expressions']:\n",
    "                value = generate(expr)\n",
    "                tac.append(('cout', value))\n",
    "        elif node['type'] == 'input':\n",
    "            for var in node['variables']:\n",
    "                tac.append((var['value'], '=', 'cin'))\n",
    "\n",
    "    generate(ast)\n",
    "    return tac\n",
    "\n",
    "# Modified parse_cpp function to include TAC generation\n",
    "def parse_cpp_with_tac(code: str,output_filename: str):\n",
    "    print('======Tokens====================================')\n",
    "    tokens = lex(code)\n",
    "    print('======Parser====================================')\n",
    "    parser = Parser(tokens)\n",
    "    ast = parser.parse()\n",
    "    tac = generate_tac(ast)\n",
    "\n",
    "    # Save TAC to a file\n",
    "    with open(output_filename, 'w') as f:\n",
    "        for line in tac:\n",
    "            f.write(' '.join(map(str, line)) + '\\n')\n",
    "            \n",
    "    return tac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example codes to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Tokens====================================\n",
      "Token: INCLUDE, Value: #include <iostream>\n",
      "Token: USING, Value: using namespace std;\n",
      "Token: TYPE, Value: int\n",
      "Token: IDENTIFIER, Value: main\n",
      "Token: LPAREN, Value: (\n",
      "Token: RPAREN, Value: )\n",
      "Token: LBRACE, Value: {\n",
      "Token: TYPE, Value: int\n",
      "Token: IDENTIFIER, Value: x\n",
      "Token: SEMICOLON, Value: ;\n",
      "Token: TYPE, Value: int\n",
      "Token: IDENTIFIER, Value: sum\n",
      "Token: ASSIGN, Value: =\n",
      "Token: NUMBER, Value: 0\n",
      "Token: SEMICOLON, Value: ;\n",
      "Token: TYPE, Value: int\n",
      "Token: IDENTIFIER, Value: t\n",
      "Token: ASSIGN, Value: =\n",
      "Token: NUMBER, Value: 10\n",
      "Token: SEMICOLON, Value: ;\n",
      "Token: WHILE, Value: while\n",
      "Token: LPAREN, Value: (\n",
      "Token: IDENTIFIER, Value: t\n",
      "Token: OP, Value: >=\n",
      "Token: NUMBER, Value: 0\n",
      "Token: RPAREN, Value: )\n",
      "Token: LBRACE, Value: {\n",
      "Token: STD_CIN, Value: cin\n",
      "Token: OP, Value: >>\n",
      "Token: IDENTIFIER, Value: x\n",
      "Token: SEMICOLON, Value: ;\n",
      "Token: IDENTIFIER, Value: t\n",
      "Token: ASSIGN, Value: =\n",
      "Token: IDENTIFIER, Value: t\n",
      "Token: OP, Value: -\n",
      "Token: NUMBER, Value: 1\n",
      "Token: SEMICOLON, Value: ;\n",
      "Token: IDENTIFIER, Value: sum\n",
      "Token: ASSIGN, Value: =\n",
      "Token: IDENTIFIER, Value: sum\n",
      "Token: OP, Value: +\n",
      "Token: IDENTIFIER, Value: x\n",
      "Token: SEMICOLON, Value: ;\n",
      "Token: RBRACE, Value: }\n",
      "Token: STD_COUT, Value: cout\n",
      "Token: OP, Value: <<\n",
      "Token: STRING_LITERAL, Value: \"Sum = \"\n",
      "Token: OP, Value: <<\n",
      "Token: IDENTIFIER, Value: sum\n",
      "Token: SEMICOLON, Value: ;\n",
      "Token: RETURN, Value: return\n",
      "Token: NUMBER, Value: 0\n",
      "Token: SEMICOLON, Value: ;\n",
      "Token: RBRACE, Value: }\n",
      "======Parser====================================\n",
      "Matched LPAREN at position 4, token: ('LPAREN', '(')\n",
      "Matched RPAREN at position 5, token: ('RPAREN', ')')\n",
      "Matched LBRACE at position 6, token: ('LBRACE', '{')\n",
      "Matched SEMICOLON at position 9, token: ('SEMICOLON', ';')\n",
      "Matched SEMICOLON at position 14, token: ('SEMICOLON', ';')\n",
      "Matched SEMICOLON at position 19, token: ('SEMICOLON', ';')\n",
      "into WHILE statement\n",
      "Matched WHILE at position 20, token: ('WHILE', 'while')\n",
      "Matched LPAREN at position 21, token: ('LPAREN', '(')\n",
      "Matched RPAREN at position 25, token: ('RPAREN', ')')\n",
      "Matched LBRACE at position 26, token: ('LBRACE', '{')\n",
      "Matched STD_CIN at position 27, token: ('STD_CIN', 'cin')\n",
      "CIN Matched ...\n",
      "Matched OP at position 28, token: ('OP', '>>')\n",
      "Matched SEMICOLON at position 30, token: ('SEMICOLON', ';')\n",
      "Matched ASSIGN at position 32, token: ('ASSIGN', '=')\n",
      "Matched SEMICOLON at position 36, token: ('SEMICOLON', ';')\n",
      "Matched ASSIGN at position 38, token: ('ASSIGN', '=')\n",
      "Matched SEMICOLON at position 42, token: ('SEMICOLON', ';')\n",
      "Matched RBRACE at position 43, token: ('RBRACE', '}')\n",
      "Matched STD_COUT at position 44, token: ('STD_COUT', 'cout')\n",
      "Matched OP at position 45, token: ('OP', '<<')\n",
      "Matched SEMICOLON at position 49, token: ('SEMICOLON', ';')\n",
      "Matched RETURN at position 50, token: ('RETURN', 'return')\n",
      "Matched SEMICOLON at position 52, token: ('SEMICOLON', ';')\n",
      "Matched RBRACE at position 53, token: ('RBRACE', '}')\n",
      "======TAC1====================================\n",
      "[('main', ':'), ('sum', '=', '0'), ('t', '=', '10'), ('L0', ':'), ('t2', '=', 't', '>=', '0'), ('if', 't2', '==', '0', 'goto', 'L1'), ('x', '=', 'cin'), ('t3', '=', 't', '-', '1'), ('t', '=', 't3'), ('t4', '=', 'sum', '+', 'x'), ('sum', '=', 't4'), ('goto', 'L0'), ('L1', ':'), ('cout', None), ('cout', 'sum'), ('return', '0')]\n"
     ]
    }
   ],
   "source": [
    "# Example codes to test\n",
    "input_code1 = \"\"\"\n",
    "#include <iostream>\n",
    "\n",
    "using namespace std;\n",
    "\n",
    "int main() {\n",
    "    int x;\n",
    "    int sum = 0;\n",
    "    int t = 10;\n",
    "\n",
    "    while (t >= 0) {\n",
    "        cin >> x;\n",
    "        t = t - 1;\n",
    "        sum = sum + x;\n",
    "    }\n",
    "\n",
    "    cout << \"Sum = \" << sum;\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Generate TAC for the input codes\n",
    "tac1 = parse_cpp_with_tac(input_code1,'TAC1')\n",
    "print('======TAC1====================================')\n",
    "print(tac1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Tokens====================================\n",
      "Token: INCLUDE, Value: #include <iostream>\n",
      "Token: USING, Value: using namespace std;\n",
      "Token: TYPE, Value: int\n",
      "Token: IDENTIFIER, Value: factorial\n",
      "Token: LPAREN, Value: (\n",
      "Token: TYPE, Value: int\n",
      "Token: IDENTIFIER, Value: n\n",
      "Token: RPAREN, Value: )\n",
      "Token: LBRACE, Value: {\n",
      "Token: IF, Value: if\n",
      "Token: LPAREN, Value: (\n",
      "Token: IDENTIFIER, Value: n\n",
      "Token: OP, Value: ==\n",
      "Token: NUMBER, Value: 0\n",
      "Token: RPAREN, Value: )\n",
      "Token: LBRACE, Value: {\n",
      "Token: RETURN, Value: return\n",
      "Token: NUMBER, Value: 1\n",
      "Token: SEMICOLON, Value: ;\n",
      "Token: RBRACE, Value: }\n",
      "Token: ELSE, Value: else\n",
      "Token: LBRACE, Value: {\n",
      "Token: RETURN, Value: return\n",
      "Token: IDENTIFIER, Value: n\n",
      "Token: OP, Value: *\n",
      "Token: IDENTIFIER, Value: factorial\n",
      "Token: LPAREN, Value: (\n",
      "Token: IDENTIFIER, Value: n\n",
      "Token: OP, Value: -\n",
      "Token: NUMBER, Value: 1\n",
      "Token: RPAREN, Value: )\n",
      "Token: SEMICOLON, Value: ;\n",
      "Token: RBRACE, Value: }\n",
      "Token: RBRACE, Value: }\n",
      "Token: TYPE, Value: int\n",
      "Token: IDENTIFIER, Value: main\n",
      "Token: LPAREN, Value: (\n",
      "Token: RPAREN, Value: )\n",
      "Token: LBRACE, Value: {\n",
      "Token: TYPE, Value: int\n",
      "Token: IDENTIFIER, Value: n\n",
      "Token: SEMICOLON, Value: ;\n",
      "Token: STD_COUT, Value: cout\n",
      "Token: OP, Value: <<\n",
      "Token: STRING_LITERAL, Value: \"Enter a number: \"\n",
      "Token: SEMICOLON, Value: ;\n",
      "Token: STD_CIN, Value: cin\n",
      "Token: OP, Value: >>\n",
      "Token: IDENTIFIER, Value: n\n",
      "Token: SEMICOLON, Value: ;\n",
      "Token: STD_COUT, Value: cout\n",
      "Token: OP, Value: <<\n",
      "Token: STRING_LITERAL, Value: \"Factorial of \"\n",
      "Token: OP, Value: <<\n",
      "Token: IDENTIFIER, Value: n\n",
      "Token: OP, Value: <<\n",
      "Token: STRING_LITERAL, Value: \" is \"\n",
      "Token: OP, Value: <<\n",
      "Token: IDENTIFIER, Value: factorial\n",
      "Token: LPAREN, Value: (\n",
      "Token: IDENTIFIER, Value: n\n",
      "Token: RPAREN, Value: )\n",
      "Token: SEMICOLON, Value: ;\n",
      "Token: RETURN, Value: return\n",
      "Token: NUMBER, Value: 0\n",
      "Token: SEMICOLON, Value: ;\n",
      "Token: RBRACE, Value: }\n",
      "======Parser====================================\n",
      "Matched LPAREN at position 4, token: ('LPAREN', '(')\n",
      "Matched RPAREN at position 7, token: ('RPAREN', ')')\n",
      "Matched LBRACE at position 8, token: ('LBRACE', '{')\n",
      "Matched IF at position 9, token: ('IF', 'if')\n",
      "Matched LPAREN at position 10, token: ('LPAREN', '(')\n",
      "Matched RPAREN at position 14, token: ('RPAREN', ')')\n",
      "Matched LBRACE at position 15, token: ('LBRACE', '{')\n",
      "Matched RETURN at position 16, token: ('RETURN', 'return')\n",
      "Matched SEMICOLON at position 18, token: ('SEMICOLON', ';')\n",
      "Matched RBRACE at position 19, token: ('RBRACE', '}')\n",
      "Matched LBRACE at position 21, token: ('LBRACE', '{')\n",
      "Matched RETURN at position 22, token: ('RETURN', 'return')\n",
      "Matched LPAREN at position 26, token: ('LPAREN', '(')\n",
      "Matched RPAREN at position 30, token: ('RPAREN', ')')\n",
      "Matched SEMICOLON at position 31, token: ('SEMICOLON', ';')\n",
      "Matched RBRACE at position 32, token: ('RBRACE', '}')\n",
      "Matched RBRACE at position 33, token: ('RBRACE', '}')\n",
      "Matched LPAREN at position 36, token: ('LPAREN', '(')\n",
      "Matched RPAREN at position 37, token: ('RPAREN', ')')\n",
      "Matched LBRACE at position 38, token: ('LBRACE', '{')\n",
      "Matched SEMICOLON at position 41, token: ('SEMICOLON', ';')\n",
      "Matched STD_COUT at position 42, token: ('STD_COUT', 'cout')\n",
      "Matched OP at position 43, token: ('OP', '<<')\n",
      "Matched SEMICOLON at position 45, token: ('SEMICOLON', ';')\n",
      "Matched STD_CIN at position 46, token: ('STD_CIN', 'cin')\n",
      "CIN Matched ...\n",
      "Matched OP at position 47, token: ('OP', '>>')\n",
      "Matched SEMICOLON at position 49, token: ('SEMICOLON', ';')\n",
      "Matched STD_COUT at position 50, token: ('STD_COUT', 'cout')\n",
      "Matched OP at position 51, token: ('OP', '<<')\n",
      "Matched LPAREN at position 59, token: ('LPAREN', '(')\n",
      "Matched RPAREN at position 61, token: ('RPAREN', ')')\n",
      "Matched SEMICOLON at position 62, token: ('SEMICOLON', ';')\n",
      "Matched RETURN at position 63, token: ('RETURN', 'return')\n",
      "Matched SEMICOLON at position 65, token: ('SEMICOLON', ';')\n",
      "Matched RBRACE at position 66, token: ('RBRACE', '}')\n",
      "======TAC2====================================\n",
      "[('factorial', ':'), ('t2', '=', 'n', '==', '0'), ('if', 't2', '==', '0', 'goto', 'L0'), ('return', '1'), ('goto', 'L1'), ('L0', ':'), ('t3', '=', 'n', '-', '1'), ('t4', '=', 'factorial', '(', 't3', ')'), ('t5', '=', 'n', '*', 't4'), ('return', 't5'), ('L1', ':'), ('main', ':'), ('cout', None), ('n', '=', 'cin'), ('cout', None), ('cout', 'n'), ('cout', None), ('t6', '=', 'factorial', '(', 'n', ')'), ('cout', 't6'), ('return', '0')]\n"
     ]
    }
   ],
   "source": [
    "input_code2 = \"\"\"\n",
    "#include <iostream>\n",
    "using namespace std;\n",
    "\n",
    "int factorial(int n) {\n",
    "    if (n == 0){\n",
    "        return 1;\n",
    "    } else {\n",
    "        return n * factorial(n - 1);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int n;\n",
    "    cout << \"Enter a number: \";\n",
    "    cin >> n;\n",
    "    cout << \"Factorial of \" << n << \" is \" << factorial(n);\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Generate TAC for the input codes\n",
    "tac2 = parse_cpp_with_tac(input_code2,'TAC2')\n",
    "print('======TAC2====================================')\n",
    "print(tac2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compiler2",
   "language": "python",
   "name": "compiler2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
